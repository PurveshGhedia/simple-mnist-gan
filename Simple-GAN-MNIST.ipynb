{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8304a170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets,transforms\n",
    "from accelerate import Accelerator\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67e6a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_dataset(batch_size=64):\n",
    "    transform_for_gan=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5),(0.5))\n",
    "    ])\n",
    "    train_dataset=datasets.MNIST('data',train=True,download=True,transform=transform_for_gan)\n",
    "    train_dataloader=torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "    \n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "496becb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGenerator(nn.Module):\n",
    "    def __init__(self,noise_dimension=100):\n",
    "        super().__init__()\n",
    "        self.noise_dimension=noise_dimension\n",
    "        \n",
    "        self.noise_to_image=nn.Sequential(\n",
    "            nn.Linear(noise_dimension,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,28*28),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        print(f\"Created Generator: {noise_dimension} -> 256 -> 512 -> {28*28}\")\n",
    "        \n",
    "    def forward(self,random_noise):\n",
    "        flat_images=self.noise_to_image(random_noise)\n",
    "        batch_size=flat_images.size(0)\n",
    "        generated_images=flat_images.view(batch_size,1,28,28)\n",
    "        \n",
    "        return generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ab259e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.image_to_decision=nn.Sequential(\n",
    "            nn.Linear(28*28,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        print(f\"Created Discriminator :{28*28} -> 512 -> 256 -> 1\")\n",
    "        \n",
    "    def forward(self, images):\n",
    "        \"\"\"Classify images as real (1) or fake (0)\"\"\"\n",
    "        batch_size = images.size(0)\n",
    "        flat_images = images.view(batch_size, -1)  # Flatten to (batch_size, 784)\n",
    "        probability_real = self.image_to_decision(flat_images)\n",
    "        return probability_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c46e3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(generator,discriminator, real_image_batch, optimizer_generator, accelerator):\n",
    "    batch_size=real_image_batch.size(0)\n",
    "    \n",
    "    #Step 1 - Generate fake images using random noise\n",
    "    random_noise=torch.randn(batch_size,generator.noise_dimension,device=accelerator.device)\n",
    "    generated_fake_images=generator(random_noise)\n",
    "    \n",
    "    #Step 2 - Take Discriminator opinion on the generated images (we want to classify the fake images as real)\n",
    "    discriminator_opinion_on_fakes=discriminator(generated_fake_images)\n",
    "    target_labels_real=torch.ones_like(discriminator_opinion_on_fakes)\n",
    "    \n",
    "    #Step 3 - Calculate loss and update generator\n",
    "    loss_function=nn.BCELoss()\n",
    "    generator_loss=loss_function(discriminator_opinion_on_fakes,target_labels_real)\n",
    "    \n",
    "    optimizer_generator.zero_grad()\n",
    "    accelerator.backward(generator_loss)\n",
    "    optimizer_generator.step()\n",
    "    \n",
    "    return generator_loss.item()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b643b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(generator,discriminator,real_images_batch,optimizer_discriminator,accelerator):\n",
    "    batch_size=real_images_batch.size(0)\n",
    "    loss_function=nn.BCELoss()\n",
    "    \n",
    "    #Step 1 - Train on REAL images\n",
    "    discriminator_opinion_on_real_images=discriminator(real_images_batch)\n",
    "    # target_labels_real=torch.zeros_like(discriminator_opinion_on_real_images)\n",
    "    target_labels_real=torch.torch.ones_like(discriminator_opinion_on_real_images)\n",
    "    loss_on_real_images = loss_function(discriminator_opinion_on_real_images, target_labels_real)\n",
    "    \n",
    "    #Step 2 - Train on FAKE images\n",
    "    random_noise=torch.randn(batch_size,generator.noise_dimension,device=accelerator.device)\n",
    "    generated_fake_images = generator(random_noise).detach()  # Don't update generator\n",
    "    discriminator_opinion_on_fakes = discriminator(generated_fake_images)\n",
    "    target_labels_fake = torch.zeros_like(discriminator_opinion_on_fakes)\n",
    "    loss_on_fake_images = loss_function(discriminator_opinion_on_fakes, target_labels_fake)\n",
    "    \n",
    "    # Step 3: Combined discriminator loss\n",
    "    total_discriminator_loss = (loss_on_real_images + loss_on_fake_images) / 2\n",
    "    \n",
    "    optimizer_discriminator.zero_grad()\n",
    "    accelerator.backward(total_discriminator_loss)\n",
    "    optimizer_discriminator.step()\n",
    "    \n",
    "    return total_discriminator_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fddbb4a-b782-431c-ad33-a061d2640d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_generated_samples(generator, epoch, accelerator, num_samples=16):\n",
    "    \"\"\"Save generated image samples to visualize progress\"\"\"\n",
    "    generator.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Generate samples\n",
    "        sample_noise = torch.randn(num_samples, generator.noise_dimension, device=accelerator.device)\n",
    "        generated_samples = generator(sample_noise)\n",
    "        \n",
    "        # Convert to numpy for plotting\n",
    "        samples_cpu = generated_samples.cpu()\n",
    "        \n",
    "        # Create grid plot\n",
    "        fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
    "        for i, ax in enumerate(axes.flat):\n",
    "            if i < num_samples:\n",
    "                # Denormalize from [-1,1] to [0,1] for display\n",
    "                img = (samples_cpu[i].squeeze() + 1) / 2\n",
    "                ax.imshow(img, cmap='gray')\n",
    "            ax.axis('off')\n",
    "        \n",
    "        plt.suptitle(f'Generated Images - Epoch {epoch}', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save image\n",
    "        os.makedirs('generated_images', exist_ok=True)\n",
    "        if isinstance(epoch, str):\n",
    "            plt.savefig(f'generated_images/{epoch}.png')\n",
    "        else:\n",
    "            plt.savefig(f'generated_images/epoch_{epoch:03d}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    generator.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "357bd89a-e3af-406a-b3b0-bd64f64eaf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overfit_single_batch_gan(generator, discriminator, train_dataloader, accelerator, iterations=1000):\n",
    "    \"\"\"\n",
    "    TESTING FUNCTION: Overfit GAN on a single batch to verify learning capability\n",
    "    If the networks can't overfit one batch, they won't work on full dataset\n",
    "    \"\"\"\n",
    "    accelerator.print(\"=== OVERFITTING TEST: Training GAN on single batch ===\")\n",
    "    \n",
    "    # Get one single batch and keep using it\n",
    "    single_batch_images, _ = next(iter(train_dataloader))\n",
    "    visualize_single_batch(single_batch_images)\n",
    "\n",
    "    #creating an even smaller batch of 10 images instead of 128\n",
    "    # small_batch = single_batch_images[:1]\n",
    "    # print(\"visualizing small batch\")\n",
    "    # visualize_single_batch(single_batch_images)\n",
    "    accelerator.print(f\"Using single batch with {single_batch_images.size(0)} images\")\n",
    "    \n",
    "    # Create optimizers\n",
    "    optimizer_generator = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    \n",
    "    # Train on the same batch repeatedly\n",
    "    for iteration in range(iterations):\n",
    "        # Train discriminator on the same batch\n",
    "        discriminator_loss = train_discriminator(\n",
    "            generator, discriminator, single_batch_images, \n",
    "            optimizer_discriminator, accelerator\n",
    "        )\n",
    "        \n",
    "        # Train generator on the same batch\n",
    "        generator_loss = train_generator(\n",
    "            generator, discriminator, single_batch_images,\n",
    "            optimizer_generator, accelerator\n",
    "        )\n",
    "        \n",
    "        # Print progress every 50 iterations\n",
    "        if (iteration + 1) % 50 == 0:\n",
    "            accelerator.print(f'Iteration {iteration+1:3d}: Gen Loss = {generator_loss:.4f}, Disc Loss = {discriminator_loss:.4f}')\n",
    "        \n",
    "        # Save samples every 100 iterations\n",
    "        if (iteration + 1) % 100 == 0:\n",
    "            save_generated_samples(generator, f'overfit_iter_{iteration+1}', accelerator)\n",
    "    \n",
    "    accelerator.print(\"Overfitting test completed! Check if losses decreased and images improved.\")\n",
    "    accelerator.print(\"If GAN can overfit one batch, it should work on full dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cf72cda-6561-4670-922d-fbbc2f9c54ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, train_dataloader, accelerator, epochs=50):\n",
    "    \"\"\"Main training loop for the GAN\"\"\"\n",
    "    # Create optimizers\n",
    "    optimizer_generator = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        total_generator_loss = 0\n",
    "        total_discriminator_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for real_images_batch, _ in train_dataloader:  # We don't need labels for GAN\n",
    "            \n",
    "            # Train discriminator first\n",
    "            discriminator_loss = train_discriminator(\n",
    "                generator, discriminator, real_images_batch, \n",
    "                optimizer_discriminator, accelerator\n",
    "            )\n",
    "            \n",
    "            # Train generator second\n",
    "            generator_loss = train_generator(\n",
    "                generator, discriminator, real_images_batch,\n",
    "                optimizer_generator, accelerator\n",
    "            )\n",
    "            \n",
    "            total_generator_loss += generator_loss\n",
    "            total_discriminator_loss += discriminator_loss\n",
    "            num_batches += 1\n",
    "        \n",
    "        # Print progress\n",
    "        avg_gen_loss = total_generator_loss / num_batches\n",
    "        avg_disc_loss = total_discriminator_loss / num_batches\n",
    "        accelerator.print(f'Epoch {epoch+1:3d}: Gen Loss = {avg_gen_loss:.4f}, Disc Loss = {avg_disc_loss:.4f}')\n",
    "        \n",
    "        # Save samples every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            save_generated_samples(generator, epoch + 1, accelerator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0384b83-e65b-48aa-9b94-6617400448e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run the educational GAN\"\"\"\n",
    "    # Initialize Accelerator for device management\n",
    "    accelerator = Accelerator()\n",
    "    accelerator.print(\"Starting Simple Educational GAN Training\")\n",
    "    \n",
    "    # Step 1: Load MNIST data\n",
    "    train_dataloader = load_mnist_dataset(batch_size=128)\n",
    "    accelerator.print(f\"Loaded MNIST dataset with {len(train_dataloader)} batches\")\n",
    "    \n",
    "    # Step 2: Create models\n",
    "    noise_dimension = 100\n",
    "    generator = SimpleGenerator(noise_dimension)\n",
    "    discriminator = SimpleDiscriminator()\n",
    "    \n",
    "    # Step 3: Prepare everything with Accelerate\n",
    "    generator, discriminator, train_dataloader = accelerator.prepare(\n",
    "        generator, discriminator, train_dataloader\n",
    "    )\n",
    "    \n",
    "    accelerator.print(f'Generator parameters: {sum(p.numel() for p in generator.parameters()):,}')\n",
    "    accelerator.print(f'Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}')\n",
    "    \n",
    "    # OPTION 1: Test if networks can learn by overfitting single batch\n",
    "    accelerator.print(\"\\nChoose training mode:\")\n",
    "    accelerator.print(\"1. Overfit single batch (testing mode)\")\n",
    "    accelerator.print(\"2. Full dataset training\")\n",
    "    \n",
    "    # For educational purposes, let's run overfitting test first\n",
    "    # overfit_single_batch_gan(generator, discriminator, train_dataloader, accelerator, iterations=1000)\n",
    "    \n",
    "    # Uncomment the line below to run full training instead:\n",
    "    train_gan(generator, discriminator, train_dataloader, accelerator, epochs=100)\n",
    "    \n",
    "    accelerator.print(\"Training completed! Check 'generated_images' folder for results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a328c6c-c3f5-415e-8998-9ce7522d43f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def visualize_single_batch(single_batch_images, n=8):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for i in range(n * n):\n",
    "        plt.subplot(n, n, i + 1)\n",
    "        plt.imshow(single_batch_images[i].squeeze().cpu(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abaf08a1-88f9-4c5b-a3cf-a44a8011b1ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Simple Educational GAN Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 28.9k/28.9k [00:00<00:00, 111kB/s]\n",
      "100%|███████████████████████████████████████| 1.65M/1.65M [00:07<00:00, 215kB/s]\n",
      "100%|██████████████████████████████████████| 4.54k/4.54k [00:00<00:00, 1.01MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MNIST dataset with 469 batches\n",
      "Created Generator: 100 -> 256 -> 512 -> 784\n",
      "Created Discriminator :784 -> 512 -> 256 -> 1\n",
      "Generator parameters: 559,632\n",
      "Discriminator parameters: 402,433\n",
      "\n",
      "Choose training mode:\n",
      "1. Overfit single batch (testing mode)\n",
      "2. Full dataset training\n",
      "Epoch   1: Gen Loss = 0.8113, Disc Loss = 0.5233\n",
      "Epoch   2: Gen Loss = 1.0575, Disc Loss = 0.4611\n",
      "Epoch   3: Gen Loss = 1.1409, Disc Loss = 0.4544\n",
      "Epoch   4: Gen Loss = 1.1585, Disc Loss = 0.4570\n",
      "Epoch   5: Gen Loss = 1.2567, Disc Loss = 0.4403\n",
      "Epoch   6: Gen Loss = 1.1974, Disc Loss = 0.4566\n",
      "Epoch   7: Gen Loss = 1.2060, Disc Loss = 0.4703\n",
      "Epoch   8: Gen Loss = 1.1589, Disc Loss = 0.4913\n",
      "Epoch   9: Gen Loss = 1.0888, Disc Loss = 0.5239\n",
      "Epoch  10: Gen Loss = 1.0899, Disc Loss = 0.5232\n",
      "Epoch  11: Gen Loss = 1.0971, Disc Loss = 0.5226\n",
      "Epoch  12: Gen Loss = 1.1227, Disc Loss = 0.5195\n",
      "Epoch  13: Gen Loss = 1.1280, Disc Loss = 0.5162\n",
      "Epoch  14: Gen Loss = 1.1290, Disc Loss = 0.5215\n",
      "Epoch  15: Gen Loss = 1.1265, Disc Loss = 0.5229\n",
      "Epoch  16: Gen Loss = 1.1003, Disc Loss = 0.5312\n",
      "Epoch  17: Gen Loss = 1.0962, Disc Loss = 0.5349\n",
      "Epoch  18: Gen Loss = 1.0650, Disc Loss = 0.5476\n",
      "Epoch  19: Gen Loss = 1.0746, Disc Loss = 0.5413\n",
      "Epoch  20: Gen Loss = 1.0857, Disc Loss = 0.5503\n",
      "Epoch  21: Gen Loss = 1.0697, Disc Loss = 0.5575\n",
      "Epoch  22: Gen Loss = 1.0835, Disc Loss = 0.5479\n",
      "Epoch  23: Gen Loss = 1.0750, Disc Loss = 0.5513\n",
      "Epoch  24: Gen Loss = 1.0672, Disc Loss = 0.5563\n",
      "Epoch  25: Gen Loss = 1.0681, Disc Loss = 0.5558\n",
      "Epoch  26: Gen Loss = 1.0759, Disc Loss = 0.5575\n",
      "Epoch  27: Gen Loss = 1.0728, Disc Loss = 0.5558\n",
      "Epoch  28: Gen Loss = 1.0722, Disc Loss = 0.5598\n",
      "Epoch  29: Gen Loss = 1.0710, Disc Loss = 0.5618\n",
      "Epoch  30: Gen Loss = 1.0658, Disc Loss = 0.5667\n",
      "Epoch  31: Gen Loss = 1.0606, Disc Loss = 0.5665\n",
      "Epoch  32: Gen Loss = 1.0652, Disc Loss = 0.5680\n",
      "Epoch  33: Gen Loss = 1.0566, Disc Loss = 0.5701\n",
      "Epoch  34: Gen Loss = 1.0539, Disc Loss = 0.5729\n",
      "Epoch  35: Gen Loss = 1.0684, Disc Loss = 0.5683\n",
      "Epoch  36: Gen Loss = 1.0636, Disc Loss = 0.5691\n",
      "Epoch  37: Gen Loss = 1.0417, Disc Loss = 0.5793\n",
      "Epoch  38: Gen Loss = 1.0469, Disc Loss = 0.5793\n",
      "Epoch  39: Gen Loss = 1.0512, Disc Loss = 0.5769\n",
      "Epoch  40: Gen Loss = 1.0448, Disc Loss = 0.5811\n",
      "Epoch  41: Gen Loss = 1.0495, Disc Loss = 0.5841\n",
      "Epoch  42: Gen Loss = 1.0446, Disc Loss = 0.5803\n",
      "Epoch  43: Gen Loss = 1.0506, Disc Loss = 0.5840\n",
      "Epoch  44: Gen Loss = 1.0474, Disc Loss = 0.5775\n",
      "Epoch  45: Gen Loss = 1.0431, Disc Loss = 0.5790\n",
      "Epoch  46: Gen Loss = 1.0501, Disc Loss = 0.5814\n",
      "Epoch  47: Gen Loss = 1.0467, Disc Loss = 0.5814\n",
      "Epoch  48: Gen Loss = 1.0350, Disc Loss = 0.5875\n",
      "Epoch  49: Gen Loss = 1.0404, Disc Loss = 0.5840\n",
      "Epoch  50: Gen Loss = 1.0326, Disc Loss = 0.5870\n",
      "Epoch  51: Gen Loss = 1.0385, Disc Loss = 0.5889\n",
      "Epoch  52: Gen Loss = 1.0282, Disc Loss = 0.5861\n",
      "Epoch  53: Gen Loss = 1.0412, Disc Loss = 0.5847\n",
      "Epoch  54: Gen Loss = 1.0427, Disc Loss = 0.5904\n",
      "Epoch  55: Gen Loss = 1.0471, Disc Loss = 0.5883\n",
      "Epoch  56: Gen Loss = 1.0311, Disc Loss = 0.5855\n",
      "Epoch  57: Gen Loss = 1.0321, Disc Loss = 0.5859\n",
      "Epoch  58: Gen Loss = 1.0314, Disc Loss = 0.5896\n",
      "Epoch  59: Gen Loss = 1.0314, Disc Loss = 0.5912\n",
      "Epoch  60: Gen Loss = 1.0257, Disc Loss = 0.5918\n",
      "Epoch  61: Gen Loss = 1.0270, Disc Loss = 0.5912\n",
      "Epoch  62: Gen Loss = 1.0323, Disc Loss = 0.5902\n",
      "Epoch  63: Gen Loss = 1.0320, Disc Loss = 0.5899\n",
      "Epoch  64: Gen Loss = 1.0238, Disc Loss = 0.5877\n",
      "Epoch  65: Gen Loss = 1.0271, Disc Loss = 0.5922\n",
      "Epoch  66: Gen Loss = 1.0306, Disc Loss = 0.5921\n",
      "Epoch  67: Gen Loss = 1.0280, Disc Loss = 0.5921\n",
      "Epoch  68: Gen Loss = 1.0223, Disc Loss = 0.5906\n",
      "Epoch  69: Gen Loss = 1.0292, Disc Loss = 0.5900\n",
      "Epoch  70: Gen Loss = 1.0247, Disc Loss = 0.5957\n",
      "Epoch  71: Gen Loss = 1.0238, Disc Loss = 0.5976\n",
      "Epoch  72: Gen Loss = 1.0138, Disc Loss = 0.5990\n",
      "Epoch  73: Gen Loss = 1.0223, Disc Loss = 0.5973\n",
      "Epoch  74: Gen Loss = 1.0203, Disc Loss = 0.5944\n",
      "Epoch  75: Gen Loss = 1.0192, Disc Loss = 0.5937\n",
      "Epoch  76: Gen Loss = 1.0197, Disc Loss = 0.5985\n",
      "Epoch  77: Gen Loss = 1.0091, Disc Loss = 0.5974\n",
      "Epoch  78: Gen Loss = 1.0101, Disc Loss = 0.6010\n",
      "Epoch  79: Gen Loss = 1.0091, Disc Loss = 0.6005\n",
      "Epoch  80: Gen Loss = 1.0069, Disc Loss = 0.6019\n",
      "Epoch  81: Gen Loss = 0.9973, Disc Loss = 0.6054\n",
      "Epoch  82: Gen Loss = 0.9999, Disc Loss = 0.6045\n",
      "Epoch  83: Gen Loss = 0.9959, Disc Loss = 0.6045\n",
      "Epoch  84: Gen Loss = 1.0097, Disc Loss = 0.6027\n",
      "Epoch  85: Gen Loss = 1.0097, Disc Loss = 0.6011\n",
      "Epoch  86: Gen Loss = 1.0053, Disc Loss = 0.6031\n",
      "Epoch  87: Gen Loss = 0.9995, Disc Loss = 0.6029\n",
      "Epoch  88: Gen Loss = 1.0011, Disc Loss = 0.6039\n",
      "Epoch  89: Gen Loss = 0.9967, Disc Loss = 0.6054\n",
      "Epoch  90: Gen Loss = 0.9965, Disc Loss = 0.6052\n",
      "Epoch  91: Gen Loss = 0.9961, Disc Loss = 0.6038\n",
      "Epoch  92: Gen Loss = 0.9958, Disc Loss = 0.6079\n",
      "Epoch  93: Gen Loss = 0.9883, Disc Loss = 0.6072\n",
      "Epoch  94: Gen Loss = 0.9836, Disc Loss = 0.6073\n",
      "Epoch  95: Gen Loss = 0.9924, Disc Loss = 0.6113\n",
      "Epoch  96: Gen Loss = 0.9860, Disc Loss = 0.6096\n",
      "Epoch  97: Gen Loss = 0.9866, Disc Loss = 0.6092\n",
      "Epoch  98: Gen Loss = 0.9825, Disc Loss = 0.6067\n",
      "Epoch  99: Gen Loss = 0.9878, Disc Loss = 0.6113\n",
      "Epoch 100: Gen Loss = 0.9773, Disc Loss = 0.6131\n",
      "Training completed! Check 'generated_images' folder for results.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
