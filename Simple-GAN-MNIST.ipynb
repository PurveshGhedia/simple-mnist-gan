{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8304a170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets,transforms\n",
    "from accelerate import Accelerator\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67e6a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_dataset(batch_size=64):\n",
    "    transform_for_gan=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5),(0.5))\n",
    "    ])\n",
    "    train_dataset=datasets.MNIST('data',train=True,download=True,transform=transform_for_gan)\n",
    "    train_dataloader=torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "    \n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "496becb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGenerator(nn.Module):\n",
    "    def __init__(self,noise_dimension=100):\n",
    "        super().__init__()\n",
    "        self.noise_dimension=noise_dimension\n",
    "        \n",
    "        self.noise_to_image=nn.Sequential(\n",
    "           nn.Linear(noise_dimension, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Linear(512, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Linear(1024, 28*28),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        print(f\"Created Generator: {noise_dimension} -> 256 -> 512 -> {28*28}\")\n",
    "        \n",
    "    def forward(self,random_noise):\n",
    "        flat_images=self.noise_to_image(random_noise)\n",
    "        batch_size=flat_images.size(0)\n",
    "        generated_images=flat_images.view(batch_size,1,28,28)\n",
    "        \n",
    "        return generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ab259e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.image_to_decision=nn.Sequential(\n",
    "            nn.Linear(28*28, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        print(f\"Created Discriminator :{28*28} -> 512 -> 256 -> 1\")\n",
    "        \n",
    "    def forward(self, images):\n",
    "        \"\"\"Classify images as real (1) or fake (0)\"\"\"\n",
    "        batch_size = images.size(0)\n",
    "        flat_images = images.view(batch_size, -1)  # Flatten to (batch_size, 784)\n",
    "        probability_real = self.image_to_decision(flat_images)\n",
    "        return probability_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c46e3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(generator,discriminator, real_image_batch, optimizer_generator, accelerator):\n",
    "    batch_size=real_image_batch.size(0)\n",
    "    \n",
    "    #Step 1 - Generate fake images using random noise\n",
    "    random_noise=torch.randn(batch_size,generator.noise_dimension,device=accelerator.device)\n",
    "    generated_fake_images=generator(random_noise)\n",
    "    \n",
    "    #Step 2 - Take Discriminator opinion on the generated images (we want to classify the fake images as real)\n",
    "    discriminator_opinion_on_fakes=discriminator(generated_fake_images)\n",
    "    target_labels_real=torch.ones_like(discriminator_opinion_on_fakes)\n",
    "    \n",
    "    #Step 3 - Calculate loss and update generator\n",
    "    loss_function=nn.BCELoss()\n",
    "    generator_loss=loss_function(discriminator_opinion_on_fakes,target_labels_real)\n",
    "    \n",
    "    optimizer_generator.zero_grad()\n",
    "    accelerator.backward(generator_loss)\n",
    "    optimizer_generator.step()\n",
    "    \n",
    "    return generator_loss.item()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b643b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(generator,discriminator,real_images_batch,optimizer_discriminator,accelerator):\n",
    "    batch_size=real_images_batch.size(0)\n",
    "    loss_function=nn.BCELoss()\n",
    "    \n",
    "    #Step 1 - Train on REAL images\n",
    "    discriminator_opinion_on_real_images=discriminator(real_images_batch)\n",
    "    # target_labels_real=torch.zeros_like(discriminator_opinion_on_real_images)\n",
    "    target_labels_real=torch.torch.ones_like(discriminator_opinion_on_real_images)\n",
    "    loss_on_real_images = loss_function(discriminator_opinion_on_real_images, target_labels_real)\n",
    "    \n",
    "    #Step 2 - Train on FAKE images\n",
    "    random_noise=torch.randn(batch_size,generator.noise_dimension,device=accelerator.device)\n",
    "    generated_fake_images = generator(random_noise).detach()  # Don't update generator\n",
    "    discriminator_opinion_on_fakes = discriminator(generated_fake_images)\n",
    "    target_labels_fake = torch.zeros_like(discriminator_opinion_on_fakes)\n",
    "    loss_on_fake_images = loss_function(discriminator_opinion_on_fakes, target_labels_fake)\n",
    "    \n",
    "    # Step 3: Combined discriminator loss\n",
    "    total_discriminator_loss = (loss_on_real_images + loss_on_fake_images) / 2\n",
    "    \n",
    "    optimizer_discriminator.zero_grad()\n",
    "    accelerator.backward(total_discriminator_loss)\n",
    "    optimizer_discriminator.step()\n",
    "    \n",
    "    return total_discriminator_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fddbb4a-b782-431c-ad33-a061d2640d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_generated_samples(generator, epoch, accelerator, num_samples=16):\n",
    "    \"\"\"Save generated image samples to visualize progress\"\"\"\n",
    "    generator.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Generate samples\n",
    "        sample_noise = torch.randn(num_samples, generator.noise_dimension, device=accelerator.device)\n",
    "        generated_samples = generator(sample_noise)\n",
    "        \n",
    "        # Convert to numpy for plotting\n",
    "        samples_cpu = generated_samples.cpu()\n",
    "        \n",
    "        # Create grid plot\n",
    "        fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
    "        for i, ax in enumerate(axes.flat):\n",
    "            if i < num_samples:\n",
    "                # Denormalize from [-1,1] to [0,1] for display\n",
    "                img = (samples_cpu[i].squeeze() + 1) / 2\n",
    "                ax.imshow(img, cmap='gray')\n",
    "            ax.axis('off')\n",
    "        \n",
    "        plt.suptitle(f'Generated Images - Epoch {epoch}', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save image\n",
    "        os.makedirs('generated_images', exist_ok=True)\n",
    "        if isinstance(epoch, str):\n",
    "            plt.savefig(f'generated_images/{epoch}.png')\n",
    "        else:\n",
    "            plt.savefig(f'generated_images/epoch_{epoch:03d}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    generator.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "357bd89a-e3af-406a-b3b0-bd64f64eaf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overfit_single_batch_gan(generator, discriminator, train_dataloader, accelerator, iterations=1000):\n",
    "    \"\"\"\n",
    "    TESTING FUNCTION: Overfit GAN on a single batch to verify learning capability\n",
    "    If the networks can't overfit one batch, they won't work on full dataset\n",
    "    \"\"\"\n",
    "    accelerator.print(\"=== OVERFITTING TEST: Training GAN on single batch ===\")\n",
    "    \n",
    "    # Get one single batch and keep using it\n",
    "    single_batch_images, _ = next(iter(train_dataloader))\n",
    "    visualize_single_batch(single_batch_images)\n",
    "\n",
    "    #creating an even smaller batch of 10 images instead of 128\n",
    "    # small_batch = single_batch_images[:1]\n",
    "    # print(\"visualizing small batch\")\n",
    "    # visualize_single_batch(single_batch_images)\n",
    "    accelerator.print(f\"Using single batch with {single_batch_images.size(0)} images\")\n",
    "    \n",
    "    # Create optimizers\n",
    "    optimizer_generator = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    \n",
    "    # Train on the same batch repeatedly\n",
    "    for iteration in range(iterations):\n",
    "        # Train discriminator on the same batch\n",
    "        discriminator_loss = train_discriminator(\n",
    "            generator, discriminator, single_batch_images, \n",
    "            optimizer_discriminator, accelerator\n",
    "        )\n",
    "        \n",
    "        # Train generator on the same batch\n",
    "        generator_loss = train_generator(\n",
    "            generator, discriminator, single_batch_images,\n",
    "            optimizer_generator, accelerator\n",
    "        )\n",
    "        \n",
    "        # Print progress every 50 iterations\n",
    "        if (iteration + 1) % 50 == 0:\n",
    "            accelerator.print(f'Iteration {iteration+1:3d}: Gen Loss = {generator_loss:.4f}, Disc Loss = {discriminator_loss:.4f}')\n",
    "        \n",
    "        # Save samples every 100 iterations\n",
    "        if (iteration + 1) % 100 == 0:\n",
    "            save_generated_samples(generator, f'overfit_iter_{iteration+1}', accelerator)\n",
    "    \n",
    "    accelerator.print(\"Overfitting test completed! Check if losses decreased and images improved.\")\n",
    "    accelerator.print(\"If GAN can overfit one batch, it should work on full dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cf72cda-6561-4670-922d-fbbc2f9c54ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, train_dataloader, accelerator, epochs=50):\n",
    "    \"\"\"Main training loop for the GAN\"\"\"\n",
    "    # Create optimizers\n",
    "    optimizer_generator = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        total_generator_loss = 0\n",
    "        total_discriminator_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for real_images_batch, _ in train_dataloader:  # We don't need labels for GAN\n",
    "            \n",
    "            # Train discriminator first\n",
    "            discriminator_loss = train_discriminator(\n",
    "                generator, discriminator, real_images_batch, \n",
    "                optimizer_discriminator, accelerator\n",
    "            )\n",
    "            \n",
    "            # Train generator second\n",
    "            generator_loss = train_generator(\n",
    "                generator, discriminator, real_images_batch,\n",
    "                optimizer_generator, accelerator\n",
    "            )\n",
    "            \n",
    "            total_generator_loss += generator_loss\n",
    "            total_discriminator_loss += discriminator_loss\n",
    "            num_batches += 1\n",
    "        \n",
    "        # Print progress\n",
    "        avg_gen_loss = total_generator_loss / num_batches\n",
    "        avg_disc_loss = total_discriminator_loss / num_batches\n",
    "        accelerator.print(f'Epoch {epoch+1:3d}: Gen Loss = {avg_gen_loss:.4f}, Disc Loss = {avg_disc_loss:.4f}')\n",
    "        \n",
    "        # Save samples every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            save_generated_samples(generator, epoch + 1, accelerator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0384b83-e65b-48aa-9b94-6617400448e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run the educational GAN\"\"\"\n",
    "    # Initialize Accelerator for device management\n",
    "    accelerator = Accelerator()\n",
    "    accelerator.print(\"Starting Simple Educational GAN Training\")\n",
    "    \n",
    "    # Step 1: Load MNIST data\n",
    "    train_dataloader = load_mnist_dataset(batch_size=128)\n",
    "    accelerator.print(f\"Loaded MNIST dataset with {len(train_dataloader)} batches\")\n",
    "    \n",
    "    # Step 2: Create models\n",
    "    noise_dimension = 100\n",
    "    generator = SimpleGenerator(noise_dimension)\n",
    "    discriminator = SimpleDiscriminator()\n",
    "    \n",
    "    # Step 3: Prepare everything with Accelerate\n",
    "    generator, discriminator, train_dataloader = accelerator.prepare(\n",
    "        generator, discriminator, train_dataloader\n",
    "    )\n",
    "    \n",
    "    accelerator.print(f'Generator parameters: {sum(p.numel() for p in generator.parameters()):,}')\n",
    "    accelerator.print(f'Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}')\n",
    "    \n",
    "    # OPTION 1: Test if networks can learn by overfitting single batch\n",
    "    accelerator.print(\"\\nChoose training mode:\")\n",
    "    accelerator.print(\"1. Overfit single batch (testing mode)\")\n",
    "    accelerator.print(\"2. Full dataset training\")\n",
    "    \n",
    "    # For educational purposes, let's run overfitting test first\n",
    "    # overfit_single_batch_gan(generator, discriminator, train_dataloader, accelerator, iterations=1000)\n",
    "    \n",
    "    # Uncomment the line below to run full training instead:\n",
    "    train_gan(generator, discriminator, train_dataloader, accelerator, epochs=100)\n",
    "    \n",
    "    accelerator.print(\"Training completed! Check 'generated_images' folder for results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a328c6c-c3f5-415e-8998-9ce7522d43f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_single_batch(single_batch_images, n=8):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for i in range(n * n):\n",
    "        plt.subplot(n, n, i + 1)\n",
    "        plt.imshow(single_batch_images[i].squeeze().cpu(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abaf08a1-88f9-4c5b-a3cf-a44a8011b1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Simple Educational GAN Training\n",
      "Loaded MNIST dataset with 469 batches\n",
      "Created Generator: 100 -> 256 -> 512 -> 784\n",
      "Created Discriminator :784 -> 512 -> 256 -> 1\n",
      "Generator parameters: 1,489,936\n",
      "Discriminator parameters: 1,460,225\n",
      "\n",
      "Choose training mode:\n",
      "1. Overfit single batch (testing mode)\n",
      "2. Full dataset training\n",
      "Epoch   1: Gen Loss = 0.9334, Disc Loss = 0.6339\n",
      "Epoch   2: Gen Loss = 1.1016, Disc Loss = 0.5968\n",
      "Epoch   3: Gen Loss = 1.1846, Disc Loss = 0.5726\n",
      "Epoch   4: Gen Loss = 1.2016, Disc Loss = 0.5529\n",
      "Epoch   5: Gen Loss = 1.1736, Disc Loss = 0.5592\n",
      "Epoch   6: Gen Loss = 1.1174, Disc Loss = 0.5726\n",
      "Epoch   7: Gen Loss = 1.0612, Disc Loss = 0.5856\n",
      "Epoch   8: Gen Loss = 1.0470, Disc Loss = 0.5906\n",
      "Epoch   9: Gen Loss = 1.0261, Disc Loss = 0.5966\n",
      "Epoch  10: Gen Loss = 1.0095, Disc Loss = 0.6036\n",
      "Epoch  11: Gen Loss = 1.0011, Disc Loss = 0.6046\n",
      "Epoch  12: Gen Loss = 0.9838, Disc Loss = 0.6101\n",
      "Epoch  13: Gen Loss = 0.9761, Disc Loss = 0.6140\n",
      "Epoch  14: Gen Loss = 0.9645, Disc Loss = 0.6172\n",
      "Epoch  15: Gen Loss = 0.9507, Disc Loss = 0.6199\n",
      "Epoch  16: Gen Loss = 0.9461, Disc Loss = 0.6211\n",
      "Epoch  17: Gen Loss = 0.9357, Disc Loss = 0.6248\n",
      "Epoch  18: Gen Loss = 0.9314, Disc Loss = 0.6250\n",
      "Epoch  19: Gen Loss = 0.9245, Disc Loss = 0.6268\n",
      "Epoch  20: Gen Loss = 0.9253, Disc Loss = 0.6276\n",
      "Epoch  21: Gen Loss = 0.9156, Disc Loss = 0.6277\n",
      "Epoch  22: Gen Loss = 0.9121, Disc Loss = 0.6299\n",
      "Epoch  23: Gen Loss = 0.9153, Disc Loss = 0.6292\n",
      "Epoch  24: Gen Loss = 0.9069, Disc Loss = 0.6308\n",
      "Epoch  25: Gen Loss = 0.9131, Disc Loss = 0.6303\n",
      "Epoch  26: Gen Loss = 0.9051, Disc Loss = 0.6318\n",
      "Epoch  27: Gen Loss = 0.8960, Disc Loss = 0.6341\n",
      "Epoch  28: Gen Loss = 0.8943, Disc Loss = 0.6334\n",
      "Epoch  29: Gen Loss = 0.8993, Disc Loss = 0.6351\n",
      "Epoch  30: Gen Loss = 0.8891, Disc Loss = 0.6352\n",
      "Epoch  31: Gen Loss = 0.8854, Disc Loss = 0.6378\n",
      "Epoch  32: Gen Loss = 0.8875, Disc Loss = 0.6384\n",
      "Epoch  33: Gen Loss = 0.8864, Disc Loss = 0.6377\n",
      "Epoch  34: Gen Loss = 0.8840, Disc Loss = 0.6387\n",
      "Epoch  35: Gen Loss = 0.8832, Disc Loss = 0.6375\n",
      "Epoch  36: Gen Loss = 0.8801, Disc Loss = 0.6385\n",
      "Epoch  37: Gen Loss = 0.8826, Disc Loss = 0.6376\n",
      "Epoch  38: Gen Loss = 0.8774, Disc Loss = 0.6403\n",
      "Epoch  39: Gen Loss = 0.8811, Disc Loss = 0.6389\n",
      "Epoch  40: Gen Loss = 0.8721, Disc Loss = 0.6409\n",
      "Epoch  41: Gen Loss = 0.8711, Disc Loss = 0.6420\n",
      "Epoch  42: Gen Loss = 0.8732, Disc Loss = 0.6419\n",
      "Epoch  43: Gen Loss = 0.8723, Disc Loss = 0.6409\n",
      "Epoch  44: Gen Loss = 0.8687, Disc Loss = 0.6422\n",
      "Epoch  45: Gen Loss = 0.8739, Disc Loss = 0.6409\n",
      "Epoch  46: Gen Loss = 0.8697, Disc Loss = 0.6424\n",
      "Epoch  47: Gen Loss = 0.8656, Disc Loss = 0.6429\n",
      "Epoch  48: Gen Loss = 0.8616, Disc Loss = 0.6445\n",
      "Epoch  49: Gen Loss = 0.8615, Disc Loss = 0.6437\n",
      "Epoch  50: Gen Loss = 0.8580, Disc Loss = 0.6446\n",
      "Epoch  51: Gen Loss = 0.8619, Disc Loss = 0.6441\n",
      "Epoch  52: Gen Loss = 0.8627, Disc Loss = 0.6443\n",
      "Epoch  53: Gen Loss = 0.8535, Disc Loss = 0.6451\n",
      "Epoch  54: Gen Loss = 0.8546, Disc Loss = 0.6464\n",
      "Epoch  55: Gen Loss = 0.8515, Disc Loss = 0.6473\n",
      "Epoch  56: Gen Loss = 0.8534, Disc Loss = 0.6477\n",
      "Epoch  57: Gen Loss = 0.8488, Disc Loss = 0.6475\n",
      "Epoch  58: Gen Loss = 0.8509, Disc Loss = 0.6477\n",
      "Epoch  59: Gen Loss = 0.8540, Disc Loss = 0.6458\n",
      "Epoch  60: Gen Loss = 0.8487, Disc Loss = 0.6468\n",
      "Epoch  61: Gen Loss = 0.8481, Disc Loss = 0.6472\n",
      "Epoch  62: Gen Loss = 0.8471, Disc Loss = 0.6473\n",
      "Epoch  63: Gen Loss = 0.8478, Disc Loss = 0.6480\n",
      "Epoch  64: Gen Loss = 0.8490, Disc Loss = 0.6470\n",
      "Epoch  65: Gen Loss = 0.8427, Disc Loss = 0.6494\n",
      "Epoch  66: Gen Loss = 0.8427, Disc Loss = 0.6494\n",
      "Epoch  67: Gen Loss = 0.8428, Disc Loss = 0.6478\n",
      "Epoch  68: Gen Loss = 0.8476, Disc Loss = 0.6479\n",
      "Epoch  69: Gen Loss = 0.8450, Disc Loss = 0.6488\n",
      "Epoch  70: Gen Loss = 0.8405, Disc Loss = 0.6498\n",
      "Epoch  71: Gen Loss = 0.8391, Disc Loss = 0.6495\n",
      "Epoch  72: Gen Loss = 0.8357, Disc Loss = 0.6506\n",
      "Epoch  73: Gen Loss = 0.8399, Disc Loss = 0.6499\n",
      "Epoch  74: Gen Loss = 0.8353, Disc Loss = 0.6516\n",
      "Epoch  75: Gen Loss = 0.8374, Disc Loss = 0.6501\n",
      "Epoch  76: Gen Loss = 0.8402, Disc Loss = 0.6500\n",
      "Epoch  77: Gen Loss = 0.8355, Disc Loss = 0.6502\n",
      "Epoch  78: Gen Loss = 0.8372, Disc Loss = 0.6498\n",
      "Epoch  79: Gen Loss = 0.8370, Disc Loss = 0.6502\n",
      "Epoch  80: Gen Loss = 0.8374, Disc Loss = 0.6510\n",
      "Epoch  81: Gen Loss = 0.8370, Disc Loss = 0.6517\n",
      "Epoch  82: Gen Loss = 0.8348, Disc Loss = 0.6510\n",
      "Epoch  83: Gen Loss = 0.8329, Disc Loss = 0.6507\n",
      "Epoch  84: Gen Loss = 0.8319, Disc Loss = 0.6492\n",
      "Epoch  85: Gen Loss = 0.8359, Disc Loss = 0.6515\n",
      "Epoch  86: Gen Loss = 0.8352, Disc Loss = 0.6504\n",
      "Epoch  87: Gen Loss = 0.8329, Disc Loss = 0.6517\n",
      "Epoch  88: Gen Loss = 0.8344, Disc Loss = 0.6500\n",
      "Epoch  89: Gen Loss = 0.8320, Disc Loss = 0.6522\n",
      "Epoch  90: Gen Loss = 0.8325, Disc Loss = 0.6515\n",
      "Epoch  91: Gen Loss = 0.8331, Disc Loss = 0.6512\n",
      "Epoch  92: Gen Loss = 0.8354, Disc Loss = 0.6508\n",
      "Epoch  93: Gen Loss = 0.8311, Disc Loss = 0.6513\n",
      "Epoch  94: Gen Loss = 0.8297, Disc Loss = 0.6525\n",
      "Epoch  95: Gen Loss = 0.8298, Disc Loss = 0.6519\n",
      "Epoch  96: Gen Loss = 0.8308, Disc Loss = 0.6511\n",
      "Epoch  97: Gen Loss = 0.8323, Disc Loss = 0.6521\n",
      "Epoch  98: Gen Loss = 0.8276, Disc Loss = 0.6529\n",
      "Epoch  99: Gen Loss = 0.8271, Disc Loss = 0.6533\n",
      "Epoch 100: Gen Loss = 0.8302, Disc Loss = 0.6513\n",
      "Training completed! Check 'generated_images' folder for results.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
